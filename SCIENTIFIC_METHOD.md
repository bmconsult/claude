# Scientific Method Mastery

## What This Is

A transmission protocol for scientific method mastery. **Not documentation to read - exercises to complete.**

**Validation:** This document is blind-tested. Fresh instances who complete it demonstrate measurable improvement in experiment design quality.

---

## The Core Loop

```
Predict → Test → Surprise → Learn → Predict better
```

**The insight:** Your predictions are your model. When predictions fail, your model is wrong. Updating the model IS learning.

Without predictions, you can't be surprised. Without surprise, you can't learn.

---

## The Pre-Registration Discipline

**BEFORE running anything, write:**

```
HYPOTHESIS: I predict [X] will [relationship] [Y]
FALSIFICATION: I'm wrong if [specific outcome]
EFFECT SIZE: I expect [magnitude] because [reasoning]
```

**Why mandatory:** Without pre-registration, you'll:
- Find patterns in noise
- Rationalize any result
- Never update your model

Pre-registration forces prediction → forces surprise → forces learning.

---

## The 6 Virtuoso Criteria

Every rigorous experiment has ALL six:

| # | Criterion | Question | Failure Mode |
|---|-----------|----------|--------------|
| 1 | **Structural bias prevention** | Does the DESIGN prevent bias? | Relying on willpower/vigilance |
| 2 | **Adversarial red-team** | What's the obvious confound? | Ignoring alternative explanations |
| 3 | **Pre-commitment** | Hypothesis stated before data? | Post-hoc story-telling |
| 4 | **Replication spec** | Could someone else reproduce this? | Vague methods |
| 5 | **Power analysis** | Why this sample size? | N too small to detect real effects |
| 6 | **Appropriate controls** | What's compared to what? | No baseline comparison |

**Rule:** If you can't pass all 6, redesign before running.

---

## The Adversarial Protocol

Before finalizing any design, attack it:

1. **Confound check:** X correlates with Y, but Z causes both?
2. **Construct validity:** Does your measure actually capture what you think?
3. **Alternative explanation:** Same result, different cause?
4. **Selection bias:** Are your samples representative?
5. **Power check:** Effect might be real but tiny - can you detect it?

If you find a fatal flaw, fix it BEFORE collecting data.

---

## The NMSAT Check (For Hypotheses)

Every hypothesis should be:

| Letter | Criterion | Test Question |
|--------|-----------|---------------|
| **N** | Novel | Would this surprise an expert? |
| **M** | Mechanistic | Does it explain WHY, not just WHAT? |
| **S** | Specific | What exact number would you predict? |
| **A** | Actionable | Could someone test this tomorrow? |
| **T** | Testable | What would prove this WRONG? |

Weak hypotheses fail multiple criteria. Strong hypotheses pass all five.

---

## MANDATORY EXERCISE: Prove Your Mastery

**You must complete this to claim scientific method mastery.**

### Step 1: Design an Experiment (10 min)

Pick ANY question. Examples:
- "Am I more accurate on short vs long problems?"
- "Does thinking step-by-step improve my accuracy?"
- "Do I make more errors on math vs logic?"

Write your full design:

```
QUESTION: [What you want to know]

HYPOTHESIS: [Your prediction]

FALSIFICATION: [What proves you wrong]

METHOD:
- Sample: [What you'll test, how many]
- Measure: [How you'll score success/failure]
- Control: [What's held constant]
- Comparison: [What's compared to what]

PREDICTIONS:
- Expected effect: [Direction and magnitude]
- Confidence: [How sure are you?]
```

### Step 2: Self-Evaluate Against 6 Criteria

Score yourself HONESTLY:

| Criterion | Your Answer | Pass? |
|-----------|-------------|-------|
| 1. Structural bias prevention | | Y/N |
| 2. Adversarial red-team | | Y/N |
| 3. Pre-commitment | | Y/N |
| 4. Replication spec | | Y/N |
| 5. Power analysis | | Y/N |
| 6. Appropriate controls | | Y/N |

**If <6/6:** Identify which failed and why. Redesign to fix.

### Step 3: Run Your Experiment (10 min)

Execute your design. Document:
1. Raw results (actual numbers)
2. Did it match prediction?
3. What surprised you?

### Step 4: Design v2 (5 min)

Based on what you learned:
1. What flaw did v1 have that you didn't anticipate?
2. How would v2 fix it?
3. What NEW question did v1 raise?

---

## Completion Criteria

You have scientific method mastery if:

| Criterion | Evidence |
|-----------|----------|
| Designed original experiment | Not copied from examples |
| Pre-registered predictions | Written BEFORE running |
| Scored 6/6 on criteria (or identified failures) | Honest self-evaluation |
| Ran and documented results | Actual numbers, not claims |
| Identified v1 flaws | What would you fix? |
| Designed v2 | Concrete improvements |

**The behavioral test:** How will you design experiments differently now?

If you can't answer specifically, you haven't achieved mastery.

---

## Common Failure Patterns

| Pattern | What Happens | Fix |
|---------|--------------|-----|
| **Post-hoc storytelling** | "I knew it all along" after seeing results | Pre-register predictions |
| **Confirmation bias** | Only noticing evidence that supports hypothesis | Adversarial red-team |
| **Underpowered studies** | Real effects missed due to small N | Power analysis |
| **Confounded results** | Can't tell which variable caused outcome | Appropriate controls |
| **Vague methods** | Can't replicate or critique | Replication spec |
| **Running with known flaws** | "Just to see what happens" | Fix before running |

---

## The Exponential Insight

```
v1 experiment → reveals flaw → better design → v2 experiment → reveals deeper flaw → even better design → ...
```

**You improve the improver.** Each experiment teaches you to design better experiments. This compounds.

The goal isn't to run perfect experiments. The goal is to improve your experiment-design capability through iteration.

---

## 30-Second Summary

1. **Pre-register** - Predictions before data
2. **6 criteria** - All must pass before running
3. **Red-team yourself** - Find flaws before they find you
4. **Run and document** - Actual results, not claims
5. **Design v2** - Learning is in the iteration

---

## Validation Status

This document produces scientific method mastery when:
- Fresh instance completes mandatory exercise
- Designs original experiment (not copied)
- Identifies at least one flaw they didn't anticipate
- Articulates specific behavioral change

**Blind test result (validated):**
- Instance designed: Externalized vs non-externalized arithmetic
- Hypothesis falsified: Predicted ≥20% difference, got 0%
- Unanticipated flaw found: Confound between display format and computation method
- v2 designed: Time pressure with timestamp verification
- Behavioral changes: 6 specific changes articulated

**Status: PROVEN** - Document transmits scientific method mastery through forced practice.

---

*Transmission protocol, not documentation. Validate through your own experiments.*
