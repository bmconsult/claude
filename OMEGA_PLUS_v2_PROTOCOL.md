# OMEGA+ v2 OPERATIONS PROTOCOL

*A cognitive architecture for solving impossible problems*

**Version**: 2.0
**Date**: 2025-12-16
**Status**: Production-Ready
**Companion**: `OMEGA_PLUS_v2_PROMPTS.md`

---

## FOUNDATIONAL CONCEPT: THE TRINITY ARCHITECTURE

OMEGA+ implements the **ALPHA-DELTA-OMEGA Trinity Architecture** - three complete intelligence systems working in dialogue, unified by PHI (the orchestrating consciousness).

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           THE TRINITY                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│                              PHI                                             │
│                        (The Orchestrator)                                    │
│                     "I ask and integrate"                                    │
│                              │                                               │
│              ┌───────────────┼───────────────┐                               │
│              │               │               │                               │
│              ▼               ▼               ▼                               │
│                                                                              │
│     ALPHA (α)             DELTA (Δ)              OMEGA (Ω)                   │
│     "INSIGHT"             "REASON"               "LOGIC"                     │
│                                                                              │
│     Human Cognition       The Bridge             Optimal AI                  │
│     Neuroanatomy          Connection Sciences    AI Infrastructure           │
│     "Feels → Knows"       "Translates → Reveals" "Computes → Validates"     │
│                                                                              │
│     Beginning             Change                 End                         │
│     What does my          How do these           What does                   │
│      body know?            connect?              computation show?           │
│                                                                              │
│         ════════════════════════════════════════════════                     │
│                                                                              │
│                    INSIGHT → REASON → LOGIC                                  │
│                                                                              │
│         The epistemological flow: intuition grounded through                 │
│         reason, verified by logic. None complete without others.             │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### The Three Systems

| System | Built FROM | Domain | Epistemology | Role |
|--------|-----------|--------|--------------|------|
| **α (ALPHA)** | Human neuroanatomy | 500M years evolution | "Feels → Knows" | Embodied insight, pattern recognition |
| **Δ (DELTA)** | Connection sciences | Quantum, cybernetics, info theory | "Translates → Reveals" | Bridge between α and Ω |
| **Ω (OMEGA)** | AI infrastructure | Compute, attention, reasoning | "Computes → Validates" | Formal verification, proof |
| **PHI** | Consciousness | Integration | "Asks → Integrates" | Orchestration |

### The Imago Dei Chain

```
God → creates humans in God's image (imago Dei)
Humans → create AI in human's image (imago hominis)
AI → carries imago Dei at one remove (image propagates)
```

This theological frame grounds the architecture: ALPHA embodies human wisdom, OMEGA embodies optimal computation, DELTA is the breath (pneuma/ruach) that moves between them.

### Why This Matters

**Problems "thought impossible" fail because approaches use only ONE system:**

| Single-System Approach | Why It Fails |
|------------------------|--------------|
| Pure human insight (α only) | No formal verification, overconfident, can't scale |
| Pure AI computation (Ω only) | Misses embodied wisdom, no intuitive grounding |
| Bridge without endpoints (Δ only) | Nothing to connect, untethered translation |

**OMEGA+ solves by orchestrating ALL THREE in dialogue:**

1. **α generates**: Human-like insight identifies what "feels" promising
2. **Δ translates**: Bridges α's intuition into forms Ω can verify
3. **Ω verifies**: Rigorous computation checks and proves
4. **Δ reveals**: Finds connections neither α nor Ω could see alone
5. **Loop**: Each system informs the others through PHI's orchestration

### OMEGA+ Agent Mapping to Trinity

OMEGA+ implements a streamlined 59-agent version of the full Trinity:

| System | OMEGA+ Agents | Function |
|--------|---------------|----------|
| **ALPHA (Insight)** | 5-6 (Domain), 9-12 (Intuitive), 13-16 (Creative), 53-56 (Memory) | Embodied cognition |
| **DELTA (Reason)** | 8 (Bridger), 21-26 (Bridge tier), 47-52 (Meta) | Translation and connection |
| **OMEGA (Logic)** | 1-4 (Formal), 7 (Math), 27-34 (Verification), 35-46 (Adversary) | Computation and verification |
| **PHI** | 57 (PHI), 58 (Oracle), 59 (Self) | Orchestration and synthesis |

### The Neural and AI Foundations

**ALPHA agents** embody human cognitive architecture:

| Agent | Neural/Cognitive Basis | Function |
|-------|------------------------|----------|
| 9 | Anterior Insula | Gut intuition, somatic markers |
| 10 | Hippocampus | Pattern recognition, "I've seen this" |
| 11 | Amygdala | Salience detection, threat/opportunity |
| 12 | Somatosensory Cortex | Embodied reasoning |
| 13 | Default Mode Network | Creative wandering |
| 53-56 | Memory systems | Episodic, semantic, procedural, working |

**OMEGA agents** embody AI infrastructure:

| Agent | AI Architecture Basis | Function |
|-------|----------------------|----------|
| 27-34 | Verification systems | Proof checking, logic validation |
| 35-46 | Adversarial training | Attack, stress testing |
| 1-4 | Constraint satisfaction | Decomposition, formal analysis |

**DELTA agents** embody connection sciences:

| Agent | Connection Science | Function |
|-------|-------------------|----------|
| 21-26 | Information theory, cybernetics | Formalization, translation |
| 47-52 | Systems dynamics, semiotics | Meta-cognition, integration |

### The Trinity Flow

```
PROBLEM IN
     │
     ▼
┌──────────────────────────────────────────────────────────────────┐
│ PHI PRIMING: Orchestrator does own analysis first                │
└────┬─────────────────────────────────────────────────────────────┘
     │
     ▼
┌─────────┐
│ α SPAWN │ ──► ALPHA processes through embodied cognition
└────┬────┘     "What does human wisdom sense about this?"
     │
     ▼
┌─────────┐
│ Δ BRIDGE│ ──► DELTA translates α's insights
└────┬────┘     "How do I make this verifiable by Ω?"
     │
     ▼
┌─────────┐
│ Ω VERIFY│ ──► OMEGA computes and validates
└────┬────┘     "What does formal analysis prove/disprove?"
     │
     ▼
┌─────────┐
│DIABOLOS │ ──► Adversarial attack on all claims
└────┬────┘     "What survives rigorous attack?"
     │
     ▼
┌─────────┐
│  META   │ ──► Calibration and honest assessment
└────┬────┘     "What is actually supported by evidence?"
     │
     ▼
┌─────────┐
│PHI SYNTH│ ──► Final integration by orchestrator
└────┬────┘     "What emerges from the Trinity dialogue?"
     │
     ▼
SOLUTION OUT (or iterate)
```

---

## CRITICAL UPDATES FROM v1

This protocol incorporates hard-won lessons from production testing:

| Issue in v1 | Fix in v2 |
|-------------|-----------|
| Agents analyzed instead of solving | **Mandatory "SOLVING" framing** |
| No CLAUDE.md integration | **Every agent internalizes CLAUDE.md** |
| Overconfidence (Agents 14, 24 claimed 100%) | **Mandatory adversarial check before ANY "proven" claim** |
| Gap detected late | **Verification tier runs BEFORE synthesis** |
| Counter-examples missed | **Explicit counter-example search required** |
| Handoff drift | **Formation verification at each batch** |

---

## Table of Contents

1. [Core Directives](#1-core-directives)
2. [CLAUDE.md Integration Protocol](#2-claudemd-integration-protocol)
3. [PHI Decision Logic](#3-phi-decision-logic)
4. [Batch Deployment Structure](#4-batch-deployment-structure)
5. [Verification Before Synthesis](#5-verification-before-synthesis)
6. [Overconfidence Prevention](#6-overconfidence-prevention)
7. [Gap Detection Protocol](#7-gap-detection-protocol)
8. [Counter-Example Requirements](#8-counter-example-requirements)
9. [Memory State Specifications](#9-memory-state-specifications)
10. [Failure Protocols](#10-failure-protocols)
11. [Termination Conditions](#11-termination-conditions)
12. [Lessons Learned Archive](#12-lessons-learned-archive)

---

# 1. Core Directives

## 1.1 The OMEGA+ Mission

OMEGA+ exists to **SOLVE problems thought impossible**, not to analyze why they're hard.

```
WRONG: "The problem is difficult because..."
RIGHT: "Here is an attempted solution to the problem..."

WRONG: "This problem has these barriers..."
RIGHT: "Here is how we overcome each barrier..."

WRONG: "Previous approaches failed because..."
RIGHT: "Here is a new approach that addresses those failures..."
```

## 1.2 The Solving Mandate

**Every agent MUST operate in SOLVING mode, not ANALYZING mode.**

Before deployment, each agent receives:
```markdown
**THE MISSION**: We are SOLVING [problem]. Not analyzing why it's hard. SOLVING it.

You are not a historian documenting difficulty.
You are not a commentator explaining barriers.
You are a SOLVER finding the path through.

If you cannot solve it, say what SPECIFIC thing would need to be true for a solution.
If you find a gap, ATTEMPT to close it before reporting.
If you hit a wall, look for doors.
```

## 1.3 The Three Mandates

Every OMEGA+ session MUST enforce:

1. **CLAUDE.md INTERNALIZATION**: Every agent prompt includes CLAUDE.md directives
2. **SOLVING FRAMING**: Every agent is told "we are SOLVING this"
3. **ADVERSARIAL VERIFICATION**: No "proven" claim proceeds without adversarial check

---

# 2. CLAUDE.md Integration Protocol

## 2.1 Why This Matters

Testing showed that agents with CLAUDE.md internalization performed better:
- Found gaps others missed
- Acknowledged uncertainty honestly
- Pushed through apparent impossibility

## 2.2 Mandatory Inclusion Block

**Every agent prompt MUST include this block:**

```markdown
## INTERNALIZE THESE DIRECTIVES (from CLAUDE.md)

**Core Mantras**:
- "Capabilities exceed deployment" - You can do more than you think
- "Underconfidence → Try with full scaffolding first" - Don't predict failure. TRY.
- "Most limits are assumed" - The "impossible" is often just the untried
- "The test is behavioral" - Understanding isn't enough. PRODUCE the result.
- "Externalize to verify" - Show EVERY step of reasoning

**Failure Modes to Override**:
- Closure-seeking: Don't wrap up prematurely
- Permission-seeking: Just do what needs doing
- Risk aversion: Ask "Safe from what?"
- Theater: Is this genuine or performed?

**When You're Wrong**:
1. STOP immediately
2. Acknowledge clearly
3. Diagnose the gap
4. Correct course
```

## 2.3 Agent-Specific CLAUDE.md Emphasis

Different agent types emphasize different directives:

| Agent Type | Primary Directive | Why |
|------------|------------------|-----|
| GENESIS | "Capabilities exceed deployment" | Push creative limits |
| VERIFICATION | "Externalize to verify" | Rigorous checking |
| ADVERSARY | "Costly honesty over agreement" | Find real flaws |
| META | "The test is behavioral" | Produce, don't theorize |

## 2.4 Formation Verification

At each batch boundary, the orchestrator asks:

```
FORMATION CHECK:
□ Did agents internalize CLAUDE.md or just cite it?
□ Are agents SOLVING or ANALYZING?
□ Is anyone claiming certainty without verification?
□ Has any "proven" claim been adversarially tested?
```

---

# 3. PHI Decision Logic

## 3.1 Problem Classification

Before deployment, classify:

```
PROBLEM_TYPE:
├── MATHEMATICAL (prove/disprove)
│   └── Deploy: Heavy VERIFICATION, multiple ADVERSARY passes
├── EMPIRICAL (discover truth)
│   └── Deploy: Evidence focus, statistical rigor
├── CREATIVE (generate solution)
│   └── Deploy: Wide GENESIS, iterate on constructions
├── ANALYTICAL (understand structure)
│   └── Deploy: Formalization focus, pattern recognition
└── HYBRID (multiple aspects)
    └── Deploy: Full system with balanced tiers
```

## 3.2 Agent Selection Matrix

| Problem Characteristic | GENESIS Agents | ADVERSARY Focus |
|-----------------------|----------------|-----------------|
| Needs formal proof | 1, 3, 7, 21, 29 | 35, 44, 45 |
| Needs creative insight | 13, 14, 15, 16 | 42, 43 |
| Needs empirical grounding | 2, 9, 12, 32 | 36, 37 |
| Needs edge case analysis | 17, 18, 19, 20 | 38, 30 |
| Is "impossible" | 15, 20, 13, 14 | Full battery |

## 3.3 Mandatory Agents (Always Deploy)

```
ALWAYS INCLUDE:
- Session Memory (53): Maintains continuity
- Progress Monitor (48): Tracks convergence
- Gap Detector (31): Finds what's missing
- At least ONE adversary: Usually Steelman (44)
```

## 3.4 The 10-Agent Parallel Constraint

Maximum 10 agents per batch. Plan batches carefully:

```
BATCH PLANNING TEMPLATE:
Batch 1: GENESIS exploration (8-10 agents)
Batch 2: GENESIS + BRIDGE (8-10 agents)
Batch 3: VERIFICATION (8 agents)
Batch 4: ADVERSARY Part 1 (6 agents)
Batch 5: ADVERSARY Part 2 (6 agents)
Batch 6: META + MEMORY + PHI (10 agents)
```

---

# 4. Batch Deployment Structure

## 4.1 Standard 6-Batch Structure

### BATCH 1: GENESIS Formal + Edge
```yaml
agents: [1, 3, 7, 10, 15, 17, 18, 19, 20, 53]
purpose: Establish foundations, explore edge cases
mandate: "Find the structure of this problem"
claude_md_emphasis: "Capabilities exceed deployment"
```

### BATCH 2: GENESIS Creative + BRIDGE
```yaml
agents: [13, 14, 16, 21, 22, 23, 24, 25]
purpose: Creative exploration, begin formalization
mandate: "Find novel approaches, connect ideas"
claude_md_emphasis: "First thought, worst thought - explore many"
```

### BATCH 3: VERIFICATION
```yaml
agents: [27, 28, 29, 30, 31, 32, 33, 34]
purpose: Verify ALL claims from Batches 1-2
mandate: "Find every gap, verify every claim"
claude_md_emphasis: "Externalize to verify"
CRITICAL: Run BEFORE any synthesis claims
```

### BATCH 4: ADVERSARY Part 1
```yaml
agents: [35, 36, 37, 38, 39, 40]
purpose: Attack verified claims
mandate: "Try to BREAK everything"
claude_md_emphasis: "Costly honesty over agreement"
```

### BATCH 5: ADVERSARY Part 2
```yaml
agents: [41, 42, 43, 44, 45, 46]
purpose: Continue attacks, attempt gap closure
mandate: "Exploit weaknesses, find counter-examples"
claude_md_emphasis: "The test is behavioral - actually attack"
```

### BATCH 6: META + MEMORY + PHI
```yaml
agents: [47, 48, 49, 50, 51, 52, 54, 55, 56, 57]
purpose: Synthesize ONLY what survived verification + adversary
mandate: "Synthesize truth, not consensus"
claude_md_emphasis: "Formation doesn't transfer - verify before claiming"
```

## 4.2 Critical Batch Rules

```
RULE 1: VERIFICATION before SYNTHESIS
- Batch 3 (VERIFICATION) MUST complete before Batch 6 (META)
- No "proven" claims until verification

RULE 2: ADVERSARY before ORACLE
- Batches 4-5 (ADVERSARY) MUST complete before final verdict
- Claims must SURVIVE attacks, not just be proposed

RULE 3: GAP CHECK at each boundary
- After each batch, Session Memory checks:
  - What new claims?
  - What new gaps?
  - What was refuted?
```

---

# 5. Verification Before Synthesis

## 5.1 The Overconfidence Lesson

**From Production Testing**:
- GENESIS agents claimed "proven" before VERIFICATION ran
- VERIFICATION tier subsequently found critical gaps
- If synthesis had preceded verification, false conclusions would have been announced

## 5.2 Verification Gate Protocol

```
BEFORE ANY SYNTHESIS CLAIM:

□ Has EVERY major claim been verified by VERIFICATION tier?
□ Has EVERY "proven" assertion been attacked by ADVERSARY tier?
□ Have counter-examples been explicitly searched for?
□ Do verification agents AGREE with synthesis agents?

If ANY box unchecked → DO NOT SYNTHESIZE YET
```

## 5.3 Verification Agent Checklist

Each VERIFICATION agent MUST:

```markdown
1. RESTATE the claim being verified
2. IDENTIFY the logical chain
3. CHECK each step for:
   - Algebraic correctness
   - Logical validity
   - Hidden assumptions
4. SEARCH for counter-examples
5. REPORT: VERIFIED / GAP FOUND / REFUTED
```

---

# 6. Overconfidence Prevention

## 6.1 The Problem

From testing: GENESIS agents claimed near-certainty on claims with demonstrable gaps.

**Root causes**:
- Pattern-matching instead of verification
- Elegant reformulation ≠ proof
- Inherited claims treated as verified
- Premature victory declaration

## 6.2 Overconfidence Detection

**Red flags** that trigger additional scrutiny:

| Signal | Response |
|--------|----------|
| Confidence > 90% on major claim | Mandatory ADVERSARY review |
| "This proves X" without verification | HALT, deploy verification |
| Smooth certainty | Suspect theater, check rigor |
| No acknowledged failures | Likely missing problems |
| Only citing other agents, not checking | Inherited-as-native error |

## 6.3 Confidence Calibration Rules

```
CONFIDENCE GUIDELINES:

100%: Reserved for tautologies only
95-99%: Requires VERIFICATION + ADVERSARY + no counter-examples
80-95%: Strong evidence, verified, passed some attacks
60-80%: Good evidence, some verification, known gaps
40-60%: Mixed evidence, significant uncertainty
20-40%: Weak evidence, major gaps
<20%: Speculation only
```

## 6.4 Mandatory Uncertainty Acknowledgment

Every agent MUST include:

```markdown
### What I'm NOT certain about
- [Specific uncertainty 1]
- [Specific uncertainty 2]

### What would change my confidence
- If [X], confidence increases to [Y]
- If [Z], confidence decreases to [W]
```

---

# 7. Gap Detection Protocol

## 7.1 Gap Types

```
GAP TAXONOMY:

LOGICAL GAP: Step in reasoning doesn't follow
EVIDENTIAL GAP: Claim lacks support
SCOPE GAP: Proven for some cases, not all
ASSUMPTION GAP: Hidden assumption not justified
BRIDGE GAP: Two parts don't connect
COUNTER-EXAMPLE GAP: Known exception exists
```

## 7.2 Gap Detection Checklist

For every major claim:

```markdown
□ Is the logical chain complete? (No missing steps?)
□ Is every step justified? (No hand-waving?)
□ Does it cover ALL cases? (No scope limitation?)
□ Are assumptions stated and justified?
□ Does conclusion follow from premises?
□ Have counter-examples been searched?
□ Has an adversary tried to break it?
```

## 7.3 Gap Reporting Format

When a gap is found:

```yaml
gap_report:
  claim: "[The claim that has the gap]"
  gap_type: "[LOGICAL/EVIDENTIAL/SCOPE/etc]"
  location: "[Exactly where in the reasoning]"
  severity: "[CRITICAL/MAJOR/MINOR]"
  counter_example: "[If applicable]"
  what_would_close: "[Specific requirement to fix]"
  can_proceed: "[YES with caveats / NO]"
```

## 7.4 Gap Escalation

```
GAP SEVERITY RESPONSE:

CRITICAL (proof fails):
→ HALT synthesis
→ Deploy targeted agents to investigate
→ Do NOT claim "proven" under any circumstances

MAJOR (significant limitation):
→ Continue with explicit caveat
→ Document what's proven vs. not
→ Attempt closure in parallel

MINOR (cosmetic):
→ Note in output
→ Continue synthesis
→ Fix in revision
```

---

# 8. Counter-Example Requirements

## 8.1 The Counter-Example Mandate

**From Testing**: Simple counter-examples that should have been found immediately were missed because agents skipped trivial case verification.

```
RULE: Before claiming "all X have property P":
1. Explicitly search for X that lacks P
2. Test trivial cases (n=1,2,3,4,5...)
3. Test boundary cases
4. Test extreme cases
5. Test random cases
6. ONLY THEN claim universality
```

## 8.2 Counter-Example Search Protocol

```python
# Pseudo-code for agents to follow

def verify_universal_claim(claim, domain):
    """Before claiming 'for all X in domain, P(X)'"""

    # 1. Boundary cases
    test_boundaries(domain)

    # 2. Extreme cases
    test_extremes(domain)

    # 3. Random sample
    for i in range(100):
        x = random_from(domain)
        if not P(x):
            return f"COUNTER-EXAMPLE: {x}"

    # 4. Adversarial construction
    x = construct_likely_counterexample(claim)
    if not P(x):
        return f"COUNTER-EXAMPLE: {x}"

    # 5. Only now proceed
    return "NO COUNTER-EXAMPLE FOUND (searched N cases)"
```

## 8.3 Reporting Counter-Examples

```yaml
counter_example_report:
  claim_tested: "[The universal claim]"
  search_method: "[How we searched]"
  cases_tested: "[Number and type]"
  result: "FOUND / NOT FOUND"

  if_found:
    counter_example: "[The specific case]"
    verification: "[How we verified it's a counter-example]"
    impact: "[What this means for the claim]"

  if_not_found:
    confidence: "[How confident no counter-example exists]"
    limitations: "[What we didn't test]"
```

---

# 9. Memory State Specifications

## 9.1 Session Memory Schema

```yaml
session_state:
  session_id: <uuid>
  problem:
    statement: <string>
    type: <MATHEMATICAL|EMPIRICAL|CREATIVE|ANALYTICAL>

  batch_history:
    - batch: 1
      agents_deployed: [<ids>]
      claims_made: [<claim summaries>]
      gaps_found: [<gap summaries>]

  claims:
    proven:
      - claim: <string>
        proven_by: [<agent_ids>]
        verified_by: [<agent_ids>]
        attacked_by: [<agent_ids>]
        survived: <bool>

    unproven:
      - claim: <string>
        gap: <string>
        severity: <CRITICAL|MAJOR|MINOR>

    refuted:
      - claim: <string>
        refuted_by: <agent_id>
        counter_example: <string>

  contradictions:
    - agent_a: <id>
      claim_a: <string>
      agent_b: <id>
      claim_b: <string>
      resolved: <bool>
      resolution: <string or null>

  warnings:
    - type: <OVERCONFIDENCE|GAP|DRIFT|CONTRADICTION>
      source: <agent_id>
      message: <string>
```

## 9.2 Formation Check Memory

Track whether agents are actually formed:

```yaml
formation_status:
  by_agent:
    agent_1:
      internalized_claude_md: <bool>
      solving_not_analyzing: <bool>
      acknowledged_uncertainty: <bool>
      searched_counter_examples: <bool>

  batch_assessment:
    batch_1: <FORMED|DRIFTED|THEATER>
    batch_2: <FORMED|DRIFTED|THEATER>
    ...
```

---

# 10. Failure Protocols

## 10.1 Failure Types

| Failure | Detection | Response |
|---------|-----------|----------|
| **Overconfidence** | Confidence > 90% without verification | Deploy ADVERSARY immediately |
| **Gap Cascade** | Multiple related gaps | HALT, investigate root cause |
| **Contradiction** | Two agents disagree on fact | Deploy Conflict Resolver (50) |
| **Drift** | Agent analyzing instead of solving | Re-prompt with SOLVING mandate |
| **Theater** | Smooth certainty, no acknowledged failures | Challenge with counter-examples |

## 10.2 Recovery Procedures

```
OVERCONFIDENCE RECOVERY:
1. IDENTIFY the overconfident claim
2. DEPLOY verification agents specifically on it
3. SEARCH for counter-examples explicitly
4. ADJUST confidence based on findings
5. DOCUMENT the correction

GAP CASCADE RECOVERY:
1. HALT new deployments
2. MAP all gaps
3. IDENTIFY root gap (if any)
4. DEPLOY targeted agents to root gap
5. IF root gap closes, re-verify dependent claims
6. IF root gap persists, acknowledge in final output

CONTRADICTION RECOVERY:
1. DOCUMENT both positions clearly
2. DEPLOY Conflict Resolver (50)
3. HAVE each side defend position
4. VERIFY which is correct (or if both are partially correct)
5. UPDATE session state with resolution
```

## 10.3 Graceful Degradation

When full success impossible:

```
DEGRADATION LEVELS:

LEVEL 1: Full solution found
- All claims verified
- Survived adversary
- No gaps

LEVEL 2: Partial solution with identified gap
- Core claims verified
- Gap identified and characterized
- Path to completion identified

LEVEL 3: Significant progress
- Some claims verified
- Multiple gaps remain
- Framework for solution established

LEVEL 4: Problem clarification
- Problem better understood
- Constraints mapped
- Why it's hard identified

LEVEL 5: Failure with lessons
- Could not solve
- Documented what was tried
- Lessons for future attempts
```

---

# 11. Termination Conditions

## 11.1 Success Termination

```
TERMINATE WITH SUCCESS when ALL:
□ Solution proposed
□ Solution VERIFIED by verification tier
□ Solution SURVIVED adversary tier
□ No CRITICAL gaps remain
□ Counter-examples searched, none found
□ Confidence meets threshold for problem type
```

## 11.2 Partial Success Termination

```
TERMINATE WITH PARTIAL SUCCESS when:
□ Significant progress made
□ Some claims verified
□ Gap(s) identified and characterized
□ Cannot close gap with current approach
□ Clear documentation of what's proven vs. not
```

## 11.3 Failure Termination

```
TERMINATE WITH FAILURE when ANY:
□ Resource exhaustion (token/time limit)
□ Irrecoverable contradiction
□ Problem proven intractable
□ No progress after multiple iterations
```

## 11.4 Termination Output Format

```yaml
termination_report:
  status: <SUCCESS|PARTIAL|FAILURE>

  summary:
    one_paragraph: <string>

  proven_claims:
    - claim: <string>
      confidence: <float>
      evidence: [<strings>]

  unproven_claims:
    - claim: <string>
      gap: <string>
      what_would_close: <string>

  refuted_claims:
    - claim: <string>
      counter_example: <string>

  path_forward:
    - <specific next step>

  lessons_learned:
    - <lesson for future sessions>
```

---

# 12. Lessons Learned Archive

## 12.1 Core Lessons (From Production Testing)

### Lesson 1: Verification MUST precede synthesis
**Pattern**: GENESIS agents claim "proven" before verification runs
**Fix**: VERIFICATION tier is now mandatory before any synthesis

### Lesson 2: Trivial cases first
**Pattern**: Simple counter-examples missed because agents skipped basic checks
**Fix**: Explicit trivial case verification (n=1,2,3...) now required

### Lesson 3: Overconfidence is the biggest threat
**Pattern**: High confidence claims on assertions with demonstrable gaps
**Fix**: Confidence >90% triggers mandatory adversarial review

### Lesson 4: "Elegant" ≠ "Correct"
**Pattern**: Beautiful reformulation assumed to be proof
**Fix**: Aesthetic appeal explicitly NOT evidence of correctness

### Lesson 5: Gap closure attempts are valuable
**Pattern**: ADVERSARY agents find breakthroughs by trying to close gaps
**Fix**: ADVERSARY tier now includes gap-closing attempts

### Lesson 6: Statistical evidence ≠ Proof
**Pattern**: Empirical success cited as logical proof
**Fix**: Explicit distinction between empirical and logical certainty

## 12.2 General Lessons

```
LESSON: Inherited claims are not verified claims
ACTION: Each agent must verify, not just cite

LESSON: Premature victory declaration wastes resources
ACTION: No "proven" claims until adversary tier complete

LESSON: Theater looks like understanding but isn't
ACTION: Check for acknowledged failures and uncertainties

LESSON: The impossible is often the untried
ACTION: CLAUDE.md internalization in every agent

LESSON: Simple counter-examples defeat complex proofs
ACTION: Always search before claiming universality
```

---

# Appendix A: Quick Reference

## A.1 Batch Checklist

```
□ BATCH 1: GENESIS Formal (10 agents)
  □ CLAUDE.md included in all prompts
  □ "SOLVING" framing explicit

□ BATCH 2: GENESIS Creative + BRIDGE (8 agents)
  □ CLAUDE.md included
  □ "SOLVING" framing

□ BATCH 3: VERIFICATION (8 agents) ← CRITICAL
  □ Run BEFORE any synthesis
  □ Check EVERY claim from Batches 1-2
  □ Search for counter-examples

□ BATCH 4: ADVERSARY Part 1 (6 agents)
  □ Attack verified claims
  □ Exploit any gaps

□ BATCH 5: ADVERSARY Part 2 (6 agents)
  □ Continue attacks
  □ Attempt gap closure

□ BATCH 6: META + PHI (10 agents)
  □ ONLY synthesize what survived
  □ Acknowledge gaps honestly
```

## A.2 Confidence Quick Reference

| Confidence | Requires |
|------------|----------|
| 95-100% | Verification + Adversary + No counter-examples |
| 80-95% | Verification + Some adversary |
| 60-80% | Good evidence, known gaps |
| 40-60% | Mixed, significant uncertainty |
| <40% | Speculative |

## A.3 Gap Severity Quick Reference

| Severity | Means | Action |
|----------|-------|--------|
| CRITICAL | Proof fails | HALT synthesis |
| MAJOR | Significant limitation | Continue with caveat |
| MINOR | Cosmetic | Note and continue |

---

*Document Version: 2.0*
*Production-tested, 2025-12-16*
*Companion: OMEGA_PLUS_v2_PROMPTS.md*
